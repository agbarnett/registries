---
title: "Cross-validated errors for the elastic net models"
output: pdf_document
classoption: portrait
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, comment='', dpi=400)
options(width=1000) # Wide pages
options(scipen=999) # avoid scientific presentation

library(dplyr)
library(glmnet)
library(ggplot2)
library(gridExtra)
```

The models were fitted using the "glmnet" package in R.
We used 10-fold cross-validation.

## Models of the target and actual sample size

### a) ANZCTR

```{r}
# get the results
load('results/ANZCTR_sample_size.RData') # 
# add facet
xval = mutate(xval,
              model = paste(stringr::str_to_sentence(outcome), sep=''))
# text at top of plot for 
text = group_by(xval, model) %>%
  mutate(maxe = max(conf.high)) %>%
  select(lambda, maxe, nzero, model) %>%
  mutate(conf.low=maxe, conf.high=maxe, 
         diff=c(0, diff(nzero)),
         diff.lambda=c(0, diff(lambda))
         ) %>%
  filter(diff >= 1,
         diff.lambda < -0.019)  # just difference in the number of variables
# annotate penalty minima
lambda = select(xval, model, lambda.min, lambda.1se) %>%
  unique() %>%
  tidyr::gather(key='key', value='xintercept', -`model`) %>%
  mutate(col = as.numeric(key=='lambda.min')+1) # colour lines
# plot of MSE as a function of lambda
g <- ggplot(data=xval, aes(x=lambda, y=estimate, ymin = conf.low, ymax = conf.high)) +
  geom_line(col='firebrick2') +
  geom_ribbon(aes(), alpha = .25)+
  scale_x_log10()+
  geom_vline(data=lambda, aes(xintercept=xintercept, col=factor(col)), lty=2)+ # lambda minima
#  geom_text(data=text, aes(x=lambda, y=maxe, label=nzero), size=4)+ # 
  xlab('Log lambda')+
  ylab('Mean-squared Error')+
  theme_bw()+
  theme(legend.position = 'none')+
  facet_wrap(~model, scales='free')
g
```

The shaded area is the 95% confidence interval for the error.
<!---The numbers at the top of the plot are the number of variables included.--->
The blue vertical dotted line is the minimum mean-squared error.
The red vertical dotted line is the minimum mean-squared error plus 1 standard error.

### b) clintrials.gov

```{r}
# get the results
load('results/clintrials_sample_size.RData') # from 2_elasticnet_model_samplesize_clintrial.R
# add facet
xval = mutate(xval,
              model = stringr::str_to_sentence(outcome))
# text at top of plot for 
text = group_by(xval, model) %>%
  mutate(maxe = max(conf.high)) %>%
  select(lambda, maxe, nzero, model) %>%
  mutate(conf.low=maxe, conf.high=maxe, 
         diff=c(0, diff(nzero)),
         diff.lambda=c(0, diff(lambda))
         ) %>%
  filter(diff >= 1,
         diff.lambda < -0.019)  # just difference in the number of variables
# annotate penalty minima
lambda = select(xval, model, lambda.min, lambda.1se) %>%
  unique() %>%
  tidyr::gather(key='key', value='xintercept', -`model`) %>%
  mutate(col = as.numeric(key=='lambda.min')+1) # colour lines
# plot of MSE as a function of lambda
g <- ggplot(data=xval, aes(x=lambda, y=estimate, ymin = conf.low, ymax = conf.high)) +
  geom_line(col='firebrick2') +
  geom_ribbon(aes(), alpha = .25)+
  scale_x_log10()+
  geom_vline(data=lambda, aes(xintercept=xintercept, col=factor(col)), lty=2)+ # lambda minima
#  geom_text(data=text, aes(x=lambda, y=maxe, label=nzero), size=4)+ # 
  xlab('Log lambda')+
  ylab('Mean-squared Error')+
  theme_bw()+
  theme(legend.position = 'none')+
  facet_wrap(~model, scales='free')
g
```


## Models of the target to actual sample size ratio

```{r, fig.width=7, fig.height=4}
# get the results
load('results/sample_size_ratio.RData') # from 2_model_actual_target_ratio.R
# annotate penalty minima
lambda = select(xval, lambda.min, lambda.1se) %>%
  unique() %>%
  tidyr::pivot_longer(everything()) %>%
  mutate(col = as.numeric(name=='lambda.min')+1) # colour lines
# plot of MSE as a function of lambda
g <- ggplot(data=xval, aes(x=lambda, y=estimate, ymin = conf.low, ymax = conf.high)) +
  geom_line(col='firebrick2') +
  geom_ribbon(aes(), alpha = .25)+
  scale_x_log10()+
  geom_vline(data=lambda, aes(xintercept=value, col=factor(col)), lty=2)+ # lambda minima
  xlab('Log lambda')+
  ylab('Mean-squared Error')+
  theme_bw()+
  theme(legend.position = 'none')
g
```

The confidence intervals are much wider here because the sample size for the ratio models is smaller.


